{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beaches (main csv + reviews csv) to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file into a dataframe\n",
    "beaches_df = pd.read_csv(\"static/data/beaches.csv\")\n",
    "beaches_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rating_url column as it was only used to retrieve reviews while scraping\n",
    "beaches_df = beaches_df.drop(['ratingurl'], axis=1)\n",
    "# new column for unique ID (Category + Rank)\n",
    "beaches_df['id'] = beaches_df['category'] + beaches_df['rank'].astype(str)\n",
    "# re-arrange columns\n",
    "beaches_df = beaches_df[['id','category','rank','name','location','imageurl','description','latitude','longitude']]\n",
    "beaches_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read beachreviews csv - merge the 2 files on id\n",
    "beachreviews_df = pd.read_csv('static/data/beachreviews.csv')\n",
    "# add id column (Category + Rank)\n",
    "beachreviews_df['id'] = beachreviews_df['category'] + beachreviews_df['rank'].astype(str)\n",
    "# rearrange columns\n",
    "beachreviews_df = beachreviews_df[['id','category','rank','rate','total_reviews','excellent','very_good','average','poor','terrible']]\n",
    "beachreviews_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two files\n",
    "beaches_merged_df = beaches_df.merge(beachreviews_df, on=['id','category','rank'])\n",
    "beaches_merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to json \n",
    "data = beaches_merged_df.to_json(orient='records')\n",
    "\n",
    "# write to file\n",
    "with open(\"static/data/beaches.json\", \"w\") as file:\n",
    "    json.dump(json.loads(data), file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for Hotels Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file into a dataframe\n",
    "hotels_df = pd.read_csv(\"static/data/hotels.csv\")\n",
    "\n",
    "# drop rating_url column as it was only used to retrieve reviews while scraping\n",
    "hotels_df = hotels_df.drop(['ratingurl'], axis=1)\n",
    "# new column for unique ID (Category + Rank)\n",
    "hotels_df['id'] = hotels_df['category'] + hotels_df['rank'].astype(str)\n",
    "# re-arrange columns\n",
    "hotels_df = hotels_df[['id','category','rank','name','location','imageurl','description','latitude','longitude']]\n",
    "\n",
    "# read beachreviews csv - merge the 2 files on id\n",
    "hotelreviews_df = pd.read_csv('static/data/hotelreviews.csv')\n",
    "# add id column (Category + Rank)\n",
    "hotelreviews_df['id'] = hotelreviews_df['category'] + hotelreviews_df['rank'].astype(str)\n",
    "# rearrange columns\n",
    "hotelreviews_df = hotelreviews_df[['id','category','rank','rate','total_reviews','excellent','very_good','average','poor','terrible']]\n",
    "\n",
    "# merge the 2 files\n",
    "hotels_merged_df = hotels_df.merge(hotelreviews_df, on=['id','category','rank'])\n",
    "\n",
    "# convert df to json \n",
    "data2 = hotels_merged_df.to_json(orient='records')\n",
    "\n",
    "# write to file\n",
    "with open(\"static/data/hotels.json\", \"w\") as file2:\n",
    "    json.dump(json.loads(data2), file2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for Things To Do category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file into a dataframe\n",
    "things_df = pd.read_csv(\"static/data/things.csv\")\n",
    "\n",
    "# drop rating_url column as it was only used to retrieve reviews while scraping\n",
    "things_df = things_df.drop(['ratingurl'], axis=1)\n",
    "# new column for unique ID (Category + Rank)\n",
    "things_df['id'] = things_df['category'] + things_df['rank'].astype(str)\n",
    "# re-arrange columns\n",
    "things_df = things_df[['id','category','rank','name','location','imageurl','description','latitude','longitude']]\n",
    "\n",
    "# read beachreviews csv - merge the 2 files on id\n",
    "thingsreviews_df = pd.read_csv('static/data/thingsreviews.csv')\n",
    "# add id column (Category + Rank)\n",
    "thingsreviews_df['id'] = thingsreviews_df['category'] + thingsreviews_df['rank'].astype(str)\n",
    "# rearrange columns\n",
    "thingsreviews_df = thingsreviews_df[['id','category','rank','rate','total_reviews','excellent','very_good','average','poor','terrible']]\n",
    "\n",
    "# merge the 2 files\n",
    "things_merged_df = things_df.merge(thingsreviews_df, on=['id','category','rank'])\n",
    "\n",
    "# convert df to json \n",
    "data3 = things_merged_df.to_json(orient='records')\n",
    "\n",
    "# write to file\n",
    "with open(\"static/data/things.json\", \"w\") as file3:\n",
    "    json.dump(json.loads(data3), file3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for Restaurants category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file into a dataframe\n",
    "restaurants_df = pd.read_csv(\"static/data/restaurants.csv\")\n",
    "\n",
    "# drop rating_url column as it was only used to retrieve reviews while scraping\n",
    "restaurants_df = restaurants_df.drop(['ratingurl'], axis=1)\n",
    "# new column for unique ID (Category + Rank)\n",
    "restaurants_df['id'] = restaurants_df['category'] + restaurants_df['rank'].astype(str)\n",
    "# re-arrange columns\n",
    "restaurants_df = restaurants_df[['id','category','rank','name','location','imageurl','description','latitude','longitude']]\n",
    "\n",
    "# read beachreviews csv - merge the 2 files on id\n",
    "restaurantreviews_df = pd.read_csv('static/data/restaurantreviews.csv')\n",
    "# add id column (Category + Rank)\n",
    "restaurantreviews_df['id'] = restaurantreviews_df['category'] + restaurantreviews_df['rank'].astype(str)\n",
    "# rearrange columns\n",
    "restaurantreviews_df = restaurantreviews_df[['id','category','rank','rate','total_reviews','excellent','very_good','average','poor','terrible']]\n",
    "\n",
    "# merge the 2 files\n",
    "restaurants_merged_df = restaurants_df.merge(restaurantreviews_df, on=['id','category','rank'])\n",
    "\n",
    "# convert df to json \n",
    "data4 = restaurants_merged_df.to_json(orient='records')\n",
    "\n",
    "# write to file\n",
    "with open(\"static/data/restaurants.json\", \"w\") as file4:\n",
    "    json.dump(json.loads(data4), file4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for Destinations category (has no review ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file into a dataframe\n",
    "destinations_df = pd.read_csv(\"static/data/destinations.csv\")\n",
    "\n",
    "# drop rating_url column as it was only used to retrieve reviews while scraping\n",
    "destinations_df = destinations_df.drop(['ratingurl'], axis=1)\n",
    "# new column for unique ID (Category + Rank)\n",
    "destinations_df['id'] = destinations_df['category'] + destinations_df['rank'].astype(str)\n",
    "# re-arrange columns\n",
    "destinations_df = destinations_df[['id','category','rank','name','location','imageurl','description','latitude','longitude']]\n",
    "\n",
    "# convert df to json \n",
    "data5 = destinations_df.to_json(orient='records')\n",
    "\n",
    "# write to file\n",
    "with open(\"static/data/destinations.json\", \"w\") as file5:\n",
    "    json.dump(json.loads(data5), file5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing columns to destinations_df and default column value to be 0\n",
    "destinations_df['total_reviews'] = 0\n",
    "destinations_df['excellent'] = 0\n",
    "destinations_df['very_good'] = 0\n",
    "destinations_df['average'] = 0\n",
    "destinations_df['poor'] = 0\n",
    "destinations_df['terrible'] = 0\n",
    "destinations_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all categories and bulk insert to Postgres SQL table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [beaches_merged_df, restaurants_merged_df, hotels_merged_df, things_merged_df, destinations_df]\n",
    "all_merged_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies for sql\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from config import conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to postgresql\n",
    "engine = create_engine(conn_string)\n",
    "\n",
    "# Autoload table from database to build metadata\n",
    "table_name = 'custreview'\n",
    "metadata = sqlalchemy.schema.MetaData(bind=engine)\n",
    "table_inspect = sqlalchemy.Table(table_name, metadata, autoload=True, autoload_with=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Session Object to Connect to DB\n",
    "# ----------------------------------------\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "# Bulk Insert the dataframe into the database table (commit changes)\n",
    "with Session() as session:        \n",
    "    all_merged_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit Close for safety\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65d580feb761fe2ba8e44a47e5fcfa7ab48146f0cbe36200890e98e34de43db0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
